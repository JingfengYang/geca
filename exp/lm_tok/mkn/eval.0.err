# --TEST
# --seed=0
# --dataset=lm
# --model_dir=model
# --n_checkpoint=10
# --device=cuda:0
# --nodedup
# --wug_size=4
# --wug_count=2
# --nocompute_adjacency
# --nouse_trie
# --template_sim=none
# --sim_window_size=2
# --variants=2
# --scan_split=add_prim_split
# --scan_file=addprim_jump
# --semparse_split=question
# --semparse_mrl=sql
# --val_fold=8
# --test_fold=9
# --lm_data_dir=/data/jda/wikidata/formatted/tok
# --n_emb=64
# --n_enc=512
# --dropout=0.0
# --nocopy_sup
# --n_epochs=512
# --n_epoch_batches=32
# --n_batch=64
# --lr=0.001
# --clip=1.0
# --sched_factor=0.5
# --nologtostderr
# --noalsologtostderr
# --log_dir=
# --verbosity=0
# --verbosity=0
# --stderrthreshold=fatal
# --showprefixforinfo
# --norun_with_pdb
# --nopdb_post_mortem
# --norun_with_profiling
# --use_cprofile_for_profiling
# --noonly_check_args
# --aug_ratio=0.0
# --test_curve
# --use_mkn
# --lm_file=lm_base.0.arpa
# --aug_lm_file=lm_aug.0.arpa
# --nohelp
# --nohelp
# --nohelpshort
# --nohelpfull
# --nohelpxml
# 
train 2157
aug 0
Loading the LM will be faster if you build a binary file.
Reading /data/jda/metacomp2/exp/lm_tok/mkn/lm_base.0.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
eval_train/ppl 4.3348
eval_train/t/p nan nan
eval_val/ppl 48.8453
eval_val/t/p nan nan
eval_test/ppl 44.2944
eval_test/t/p nan nan
# --TEST
# --seed=0
# --dataset=lm
# --model_dir=model
# --n_checkpoint=10
# --device=cuda:0
# --nodedup
# --wug_size=4
# --wug_count=2
# --nocompute_adjacency
# --nouse_trie
# --template_sim=none
# --sim_window_size=2
# --variants=2
# --scan_split=add_prim_split
# --scan_file=addprim_jump
# --semparse_split=question
# --semparse_mrl=sql
# --val_fold=8
# --test_fold=9
# --lm_data_dir=/data/jda/wikidata/formatted/tok
# --n_emb=64
# --n_enc=512
# --dropout=0.0
# --nocopy_sup
# --n_epochs=512
# --n_epoch_batches=32
# --n_batch=64
# --lr=0.001
# --clip=1.0
# --sched_factor=0.5
# --nologtostderr
# --noalsologtostderr
# --log_dir=
# --verbosity=0
# --verbosity=0
# --stderrthreshold=fatal
# --showprefixforinfo
# --norun_with_pdb
# --nopdb_post_mortem
# --norun_with_profiling
# --use_cprofile_for_profiling
# --noonly_check_args
# --aug_ratio=0.1
# --test_curve
# --use_mkn
# --lm_file=lm_base.0.arpa
# --aug_lm_file=lm_aug.0.arpa
# --nohelp
# --nohelp
# --nohelpshort
# --nohelpfull
# --nohelpxml
# 
train 2157
aug 0
Loading the LM will be faster if you build a binary file.
Reading /data/jda/metacomp2/exp/lm_tok/mkn/lm_base.0.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Loading the LM will be faster if you build a binary file.
Reading /data/jda/metacomp2/exp/lm_tok/mkn/lm_aug.0.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
eval_train/ppl 3.4937
eval_train/t/p -27.1564568295 6.23018861562e-140
eval_val/ppl 48.3196
eval_val/t/p -3.52738636956 0.000445430957368
eval_test/ppl 44.1153
eval_test/t/p -1.58559438925 0.113326066421
# --TEST
# --seed=0
# --dataset=lm
# --model_dir=model
# --n_checkpoint=10
# --device=cuda:0
# --nodedup
# --wug_size=4
# --wug_count=2
# --nocompute_adjacency
# --nouse_trie
# --template_sim=none
# --sim_window_size=2
# --variants=2
# --scan_split=add_prim_split
# --scan_file=addprim_jump
# --semparse_split=question
# --semparse_mrl=sql
# --val_fold=8
# --test_fold=9
# --lm_data_dir=/data/jda/wikidata/formatted/tok
# --n_emb=64
# --n_enc=512
# --dropout=0.0
# --nocopy_sup
# --n_epochs=512
# --n_epoch_batches=32
# --n_batch=64
# --lr=0.001
# --clip=1.0
# --sched_factor=0.5
# --nologtostderr
# --noalsologtostderr
# --log_dir=
# --verbosity=0
# --verbosity=0
# --stderrthreshold=fatal
# --showprefixforinfo
# --norun_with_pdb
# --nopdb_post_mortem
# --norun_with_profiling
# --use_cprofile_for_profiling
# --noonly_check_args
# --aug_ratio=0.2
# --test_curve
# --use_mkn
# --lm_file=lm_base.0.arpa
# --aug_lm_file=lm_aug.0.arpa
# --nohelp
# --nohelp
# --nohelpshort
# --nohelpfull
# --nohelpxml
# 
train 2157
aug 0
Loading the LM will be faster if you build a binary file.
Reading /data/jda/metacomp2/exp/lm_tok/mkn/lm_base.0.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Loading the LM will be faster if you build a binary file.
Reading /data/jda/metacomp2/exp/lm_tok/mkn/lm_aug.0.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
eval_train/ppl 3.3467
eval_train/t/p -30.5479123238 1.31123757406e-170
eval_val/ppl 48.2585
eval_val/t/p -3.40537456916 0.000696184049846
eval_test/ppl 44.1346
eval_test/t/p -1.23504949948 0.21726600031
# --TEST
# --seed=0
# --dataset=lm
# --model_dir=model
# --n_checkpoint=10
# --device=cuda:0
# --nodedup
# --wug_size=4
# --wug_count=2
# --nocompute_adjacency
# --nouse_trie
# --template_sim=none
# --sim_window_size=2
# --variants=2
# --scan_split=add_prim_split
# --scan_file=addprim_jump
# --semparse_split=question
# --semparse_mrl=sql
# --val_fold=8
# --test_fold=9
# --lm_data_dir=/data/jda/wikidata/formatted/tok
# --n_emb=64
# --n_enc=512
# --dropout=0.0
# --nocopy_sup
# --n_epochs=512
# --n_epoch_batches=32
# --n_batch=64
# --lr=0.001
# --clip=1.0
# --sched_factor=0.5
# --nologtostderr
# --noalsologtostderr
# --log_dir=
# --verbosity=0
# --verbosity=0
# --stderrthreshold=fatal
# --showprefixforinfo
# --norun_with_pdb
# --nopdb_post_mortem
# --norun_with_profiling
# --use_cprofile_for_profiling
# --noonly_check_args
# --aug_ratio=1.0
# --test_curve
# --use_mkn
# --lm_file=lm_base.0.arpa
# --aug_lm_file=lm_aug.0.arpa
# --nohelp
# --nohelp
# --nohelpshort
# --nohelpfull
# --nohelpxml
# 
train 2157
aug 0
Loading the LM will be faster if you build a binary file.
Reading /data/jda/metacomp2/exp/lm_tok/mkn/lm_base.0.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
Loading the LM will be faster if you build a binary file.
Reading /data/jda/metacomp2/exp/lm_tok/mkn/lm_aug.0.arpa
----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100
****************************************************************************************************
eval_train/ppl 3.0470
eval_train/t/p -37.5398472327 9.07732270063e-238
eval_val/ppl 48.4717
eval_val/t/p -1.62299262817 0.105014590451
eval_test/ppl 44.5166
eval_test/t/p 1.26015763853 0.208072500324
